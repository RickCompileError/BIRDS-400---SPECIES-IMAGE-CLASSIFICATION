# -*- coding: utf-8 -*-
"""BIRDS 400 - SPECIES IMAGE CLASSIFICATION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12P6v7tf-YiqrEFR3XLrHaZyW7Pyg2YoM
"""

!pip install kaggle
from google.colab import files
files.upload()
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets list
!kaggle datasets download -d gpiosenka/100-bird-species

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

import tensorflow as tf

from tensorflow import keras

print('tensorflow version: ', tf.__version__)

!unzip 100-bird-species.zip -d dataset

# Setting Data Path
BASE_DIR = os.getcwd() + '/dataset'
print('BASE_DIR: ', os.listdir(BASE_DIR))
TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VALID_DIR = os.path.join(BASE_DIR, 'valid')
TEST_DIR = os.path.join(BASE_DIR, 'test')

# Get all class name and its length
CATEGORIES = sorted(os.listdir(TRAIN_DIR))
category_count = len(CATEGORIES)
print('toatl categories: ', category_count)
print('CATEGORIES: ', CATEGORIES)

# Test loading iamge and analysis image shape
one_mpimg = mpimg.imread(os.path.join(TRAIN_DIR, CATEGORIES[0], '001.jpg'))
plt.imshow(one_mpimg)
print('Image shape is: ', one_mpimg.shape)

# Try to print rgb image seperately

fig, axes = plt.subplots(1, 4, figsize=(16,4))
axes[0].imshow(one_mpimg)
axes[1].imshow(one_mpimg[:,:,0])
axes[2].imshow(one_mpimg[:,:,1])
axes[3].imshow(one_mpimg[:,:,2])
plt.show()

# Convert RGB to Gray
one_gray_mpimg = tf.image.rgb_to_grayscale(one_mpimg)
IMG_SHAPE = one_gray_mpimg.shape
plt.imshow(tf.squeeze(one_gray_mpimg))
print("Image Shape: ", IMG_SHAPE)

# Try to print more than one image at once

fig, axes = plt.subplots(3, 3, figsize=(12,12))
for i, dirname in enumerate(CATEGORIES[:9]):
    ax = axes[i//3, i%3]
    one_img_path = os.path.join(TRAIN_DIR, dirname, '001.jpg')
    img = mpimg.imread(one_img_path)
    ax.imshow(img)
    ax.set_title('{}'.format(dirname))
plt.show()

# Global Setting
BATCH_SIZE = 50
IMG_HEIGHT = IMG_SHAPE[0]
IMG_WIDTH = IMG_SHAPE[1]

#  Preprocessing Image Data

# Training data
train_dataset = keras.utils.image_dataset_from_directory(
    TRAIN_DIR,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=123,
    batch_size = BATCH_SIZE)
class_names = train_dataset.class_names
train_dataset = train_dataset.map(lambda x, y: (tf.image.rgb_to_grayscale(x), y))
train_groups = len(train_dataset)
# print(train_dataset)
# train_dataset.
# tf.rgb_to_grayscale(train_dataset)

# Validating data
valid_dataset = keras.utils.image_dataset_from_directory(
    VALID_DIR,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=123,
    batch_size = BATCH_SIZE)
valid_dataset = valid_dataset.map(lambda x, y: (tf.image.rgb_to_grayscale(x), y))
valid_groups = len(valid_dataset)

# Testing data
test_dataset = keras.utils.image_dataset_from_directory(
    TEST_DIR,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=123,
    batch_size = BATCH_SIZE)
test_dataset = test_dataset.map(lambda x, y: (tf.image.rgb_to_grayscale(x), y))
test_groups = len(test_dataset)

print(class_names)

# Display the shape of the batch of the image and label
for image_batch, label_batch in train_dataset:
    print(image_batch.shape)
    print(label_batch.shape)
    break

# For buffer prefetching
# Dataset.cache will keep the images in memory after first epoch
# Dataset.prefetch overlaps data preprocessing and model execution while training
# AUTOTUNE = tf.data.AUTOTUNE
# train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)
# valid_dataset = valid_dataset.cache().prefetch(buffer_size=AUTOTUNE)
# test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)

from keras.layers import Input, Rescaling, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense, Activation
# Build Model
model = keras.Sequential([
    # Input
    Input(IMG_SHAPE),
    
    # Standardize the data
    Rescaling(1./255),

    # CNN
    Conv2D(filters=128, kernel_size=(3,3), padding='same'), # 224x224
    Activation('relu'),
    MaxPooling2D(pool_size=(2,2)), # 112x112
    BatchNormalization(),

    Conv2D(filters=64, kernel_size=(3,3), padding='same'), # 112x112
    Activation('relu'),
    MaxPooling2D(pool_size=(2,2)), # 56x56
    BatchNormalization(),
    
    Conv2D(filters=32, kernel_size=(3,3), padding='same'), # 56x56
    Activation('relu'),
    MaxPooling2D(pool_size=(2,2)), # 28x28
    BatchNormalization(),

    Conv2D(filters=16, kernel_size=(3,3), padding='same'), # 28x28
    Activation('relu'),
    BatchNormalization(),
    Dropout(0.2), # 56 --> 45
    
    # DNN
    Flatten(),
    Dense(512, kernel_initializer='normal'),
    Activation('relu'),
    Dropout(0.5),
    Dense(category_count),
    Activation('softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# Training Setting
EPOCHES = 25
EARLY_STOPPING = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)
history = model.fit(train_dataset,
                    steps_per_epoch = train_groups,
                    epochs = EPOCHES,
                    validation_data = valid_dataset,
                    validation_steps = valid_groups,
                    callbacks = [EARLY_STOPPING]),

results = model.evaluate(test_dataset)
print("Accuracy: %.2f%%" % (results[1]*100))

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(1,5)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()